name: Dataset Generation and Validation

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  schedule:
    - cron: '0 2 * * 1'

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.8", "3.9", "3.10", "3.11"]
        exclude:
          - os: windows-latest
            python-version: "3.8"
          - os: macos-latest
            python-version: "3.8"

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8 black pandas numpy scipy

      - name: Lint with flake8
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Check code formatting with black
        run: black --check --diff .

      - name: Test dataset generation
        run: python dataset_generator.py

      - name: Validate generated dataset
        run: python validate_dataset.py --data-dir generated_data

      - name: Run unit tests
        run: pytest tests/ -v --cov=. --cov-report=xml --cov-report=html

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.9'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  dataset-integrity:
    runs-on: ubuntu-latest
    needs: test

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate dataset with different seeds
        run: python -c '
from dataset_generator import RequirementsDatasetGenerator
import numpy as np

np.random.seed(42)
gen1 = RequirementsDatasetGenerator()
gen1.generate_complete_dataset("test_data_1")

np.random.seed(42)
gen2 = RequirementsDatasetGenerator()
gen2.generate_complete_dataset("test_data_2")
'

      - name: Check reproducibility
        run: python -c '
import pandas as pd

df1 = pd.read_csv("test_data_1/participants.csv")
df2 = pd.read_csv("test_data_2/participants.csv")

if df1.equals(df2):
    print("✅ Dataset generation is reproducible")
else:
    print("❌ Dataset generation is not reproducible")
    exit(1)
'

  statistical-validation:
    runs-on: ubuntu-latest
    needs: test

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pandas numpy scipy

      - name: Generate and validate statistical properties
        run: python -c '
from dataset_generator import RequirementsDatasetGenerator
import pandas as pd
from scipy import stats
import numpy as np

gen = RequirementsDatasetGenerator()
gen.generate_complete_dataset()

results = pd.read_csv("generated_data/participant_results.csv")
control = results[results["group_assignment"] == "Control"]
treatment = results[results["group_assignment"] == "Treatment"]

control_mean = control["requirements_identified"].mean()
treatment_mean = treatment["requirements_identified"].mean()
improvement = ((treatment_mean - control_mean) / control_mean) * 100

print(f"Control mean: {control_mean:.1f}")
print(f"Treatment mean: {treatment_mean:.1f}")
print(f"Improvement: {improvement:.1f}%")

t_stat, p_value = stats.ttest_ind(treatment["requirements_identified"],
                                  control["requirements_identified"])
print(f"T-statistic: {t_stat:.3f}, p-value: {p_value:.6f}")

if p_value >= 0.001:
    print("❌ Results not statistically significant at p < 0.001")
    exit(1)
else:
    print("✅ Statistical validation passed")
'
