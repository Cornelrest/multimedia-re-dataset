name: Dataset Generation and Validation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly to ensure dataset generation remains stable
    - cron: '0 2 * * 1'

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.8", "3.9", "3.10", "3.11"]
        exclude:
          # Reduce matrix size for efficiency
          - os: windows-latest
            python-version: "3.8"
          - os: macos-latest
            python-version: "3.8"

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Check code formatting with black
      run: |
        black --check --diff .

    - name: Test dataset generation
      run: |
        python dataset_generator.py
        
    - name: Validate generated dataset
      run: |
        python validate_dataset.py --data-dir generated_data

    - name: Run unit tests
      run: |
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html

    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.9'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  dataset-integrity:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Generate dataset with different seeds
      run: |
        # Test reproducibility with same seed
        python -c "
        from dataset_generator import RequirementsDatasetGenerator
        import numpy as np
        
        # Generate dataset twice with same seed
        np.random.seed(42)
        gen1 = RequirementsDatasetGenerator()
        gen1.generate_complete_dataset('test_data_1')
        
        np.random.seed(42) 
        gen2 = RequirementsDatasetGenerator()
        gen2.generate_complete_dataset('test_data_2')
        "
        
    - name: Check reproducibility
      run: |
        python -c "
        import pandas as pd
        import numpy as np
        
        # Compare datasets for reproducibility
        df1 = pd.read_csv('test_data_1/participants.csv')
        df2 = pd.read_csv('test_data_2/participants.csv')
        
        if df1.equals(df2):
            print('✅ Dataset generation is reproducible')
        else:
            print('❌ Dataset generation is not reproducible')
            exit(1)
        "

  statistical-validation:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Generate and validate statistical properties
      run: |
        python -c "
        from dataset_generator import RequirementsDatasetGenerator
        import pandas as pd
        from scipy import stats
        import numpy as np
        
        # Generate dataset
        gen = RequirementsDatasetGenerator()
        gen.generate_complete_dataset()
        
        # Load and validate statistical properties
        results = pd.read_csv('generated_data/participant_results.csv')
        control = results[results['group_assignment'] == 'Control']
        treatment = results[results['group_assignment'] == 'Treatment']
        
        # Check key statistical properties
        control_mean = control['requirements_identified'].mean()
        treatment_mean = treatment['requirements_identified'].mean()
        improvement = ((treatment_mean - control_mean) / control_mean) * 100
        
        print(f'Control mean: {control_mean:.1f}')
        print(f'Treatment mean: {treatment_mean:.1f}') 
        print(f'Improvement: {improvement:.1f}%')
        
        # Validate statistical significance
        t_stat, p_value = stats.ttest_ind(treatment['requirements_identified'], 
                                         control['requirements_identified'])
        print(f'T-statistic: {t_stat:.3f}, p-value: {p_value:.6f}')
        
        # Ensure statistical significance
        if p_value >= 0.001:
            print('❌ Results not statistically significant at p < 0.001')
            exit(1)
        else:
            print('✅ Statistical validation passed')
        "

  package-test:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"
        
    - name: Test package installation
      run: |
        python -m pip install --upgrade pip
        pip install build twine
        
        # Build package
        python -m build
        
        # Check package
        twine check dist/*
        
        # Install package locally
        pip install dist/*.whl
        
        # Test installed package
        python -c "
        from dataset_generator import RequirementsDatasetGenerator
        print('✅ Package installed successfully')
        "

  documentation:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"
        
    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install sphinx sphinx-rtd-theme myst-parser
        
    - name: Build documentation
      run: |
        # Create simple docs structure if it doesn't exist
        mkdir -p docs
        if [ ! -f "docs/conf.py" ]; then
          echo "Creating basic Sphinx configuration..."
          sphinx-quickstart -q -p "Requirements Engineering Dataset" \
                            -a "Cornelius Chimuanya Okechukwu" \
                            -v "1.0.0" --ext-autodoc --ext-viewcode \
                            --makefile --no-batchfile docs
        fi
        
        # Build documentation
        cd docs && make html
        
    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v3
      with:
        name: documentation
        path: docs/_build/html/

  release-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')
    needs: [test, dataset-integrity, statistical-validation, package-test]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"
        
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
        
    - name: Build package
      run: python -m build
      
    - name: Upload to TestPyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.TEST_PYPI_API_TOKEN }}
      run: |
        twine upload --repository testpypi dist/*